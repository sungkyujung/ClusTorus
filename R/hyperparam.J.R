#' Selecting optimal number of mixture components based on various criteria
#'
#' \code{hyperparam.J} evaluates criterion for each \code{icp.torus} objects, and select
#'   the optimal number of mixture components based on the evaluated criterion.
#'
#' @param data n x d matrix of toroidal data on \eqn{[0, 2\pi)^d}
#'   or \eqn{[-\pi, \pi)^d}
#' @param icp.torus.objects a list whose elements are icp.torus objects, generated by
#'   \code{icp.torus.score}.
#' @param option a string one of "risk", "AIC", or "BIC", which determines the criterion
#'   for the model selection. "risk" is based on the negative log-likelihood, "AIC" for the
#'   Akaike Information Criterion, and "BIC" for the Bayesian Information Criterion.
#' @return returns a list object which contains a \code{data.frame} for
#'   the evaluated criterion corresponding to each number of components, the optimal
#'   number of components, and the corresponding \code{icp.torus} object.
#' @export
#' @seealso \code{\link[ClusTorus]{icp.torus.score}}, \code{\link[ClusTorus]{hyperparam.torus}},
#'   \code{\link[ClusTorus]{hyperparam.alpha}}
#' @references Akaike (1974), "A new look at the statistical model identification",
#'   Schwarz, Gideon E. (1978), "Estimating the dimension of a model"
#' @examples
#' \donttest{
#' data <- toydata2[, 1:2]
#' n <- nrow(data)
#' split.id <- rep(2, n)
#' split.id[sample(n, floor(n/2))] <- 1
#' Jvec <- 3:35
#' icp.torus.objects <- list()
#' for (j in Jvec){
#'   icp.torus.objects[[j]] <- icp.torus.score(data, split.id = split.id, method = "kmeans",
#'                                             kmeansfitmethod = "general", init = "h",
#'                                             J = j, verbose = TRUE)
#' }
#' hyperparam.J(data, icp.torus.objects, option = "risk")
#' }

hyperparam.J <- function(data, icp.torus.objects, option = c("risk", "AIC", "BIC")){

  if (is.null(data)) {stop("data must be input.")}
  if (is.null(icp.torus.objects)) {stop("icp.torus.objects must be input.")}
  if (!is.list(icp.torus.objects)) {stop("icp.torus.objects must be a list.")}
  if (!is.matrix(data)) {data <- as.matrix(data)}
  data <- on.torus(data)

  option <- match.arg(option)

  Ivec <- c()
  for (i in 1:length(icp.torus.objects)){
    if (!is.null(icp.torus.objects[[i]])){
      if (class(icp.torus.objects[[i]]) != "icp.torus") {
        stop("invalid input: the elements of icp.torus.objects must be icp.torus objects.")
      }
      Ivec <- c(Ivec, i)
    }
  }
  split.id <- icp.torus.objects[[Ivec[1]]]$split.id
  d <- ncol(data)
  n2 <- icp.torus.objects[[Ivec[1]]]$n2

  # option default is risk.
  if (is.null(option)) { option <- "risk" }

  if(icp.torus.objects[[Ivec[1]]]$method == "mixture") {
    method <- "mixture"
    mixturefitmethod <- icp.torus.objects[[Ivec[1]]]$fittingmethod
  } else if(icp.torus.objects[[Ivec[1]]]$method == "kmeans") {
    method <- "kmeans"
    kmeansfitmethod <- icp.torus.objects[[Ivec[1]]]$fittingmethod
  } else {stop("method kde is not supported.")}

  for (i in Ivec){
    if (method == icp.torus.objects[[i]]$method) {next}
    else {stop("icp.torus objects must share the same method.")}
  }
  output <- list()
  IC <- data.frame()
  # 1. kmeans -----------------------------------------------------
  if (method == "kmeans"){

    # preparing the number of model parameters
    if (kmeansfitmethod == "homogeneous-circular"){
      k <- d + 1
    } else if (kmeansfitmethod == "heterogeneous-circular"){
      k <- d + 2
    } else {k <- (d + 1)*(d + 2)/2}
    for (i in Ivec){
      j <- length(icp.torus.objects[[i]]$ellipsefit$c)

      if (is.null(icp.torus.objects[[i]])) {next}
      # approximated 2 * log-likelihood for normal approximation
      sum.conformity.scores <- sum(icp.torus.objects[[i]]$score_ellipse) + n2 * d * log(2 * pi)

      # evaluating 2 * log-likelihood for AIC/BIC
      if (option != "risk") {
        sum.conformity.scores <- 2 * icp.torus.objects[[i]]$ellipsefit$loglkhd
        nsingular <- length(icp.torus.objects[[i]]$ellipsefit$singular)
      }

      # penalty for risk/AIC/BIC
      penalty <- ifelse(option == "AIC", 2,
                        ifelse(option == "BIC", log(n2), 0))

      # evaluate risk/AIC/BIC
      # nsingular term corrects the conformity score for the singular matrices
      criterion <- - sum.conformity.scores + (k * j - 1) * penalty +
        ifelse(option != "risk", nsingular * ((log(1e+6^(d/2 - 1))) + d * log((2*pi))), 0)
      IC <- rbind(IC, data.frame(J = j, criterion = criterion))
    }

    IC.index <- which.min(IC$criterion)
    Jhat <- IC[IC.index, 1]
  }
  # 2. mixture ----------------------------------------------------
  else if (method == "mixture"){

    # preparing the number of model parameters
    if (mixturefitmethod == "circular"){
      k <- d + 2
    } else if (mixturefitmethod == "axis-aligned"){
      k <- 2 * d + 1
    } else if (mixturefitmethod == "general"){
      k <- (d + 1)*(d + 2)/2
    } else stop("Bayesian is not implemented yet.")

    for (i in Ivec){
      if (is.null(icp.torus.objects[[i]])) {next}
      j <- length(icp.torus.objects[[i]]$ellipsefit$c)

      # likelihood for mixture model
      sum.conformity.scores <- sum(log(icp.torus.objects[[i]]$score))

      # evaluating log-likelihood for AIC/BIC
      if (option != "risk") {
        sum.conformity.scores <- icp.torus.objects[[i]]$fit$loglkhd.seq[length(icp.torus.objects[[i]]$fit$loglkhd.seq)]
      }

      # penalty for risk/AIC/BIC
      penalty <- ifelse(option == "AIC", 2,
                        ifelse(option == "BIC", log(n2), 0))

      # evaluate risk/AIC/BIC
      criterion <- - 2 * sum.conformity.scores + (k * j - 1) * penalty
      IC <- rbind(IC, data.frame(J = j, criterion = criterion))
    }

    IC.index <- which.min(IC$criterion)
    Jhat <- IC[IC.index, 1]
  }

  output$criterion <- option
  output$IC.results <- IC
  output$Jhat <- Jhat
  output$icp.torus <- icp.torus.objects[[Jhat]]

  return(structure(output, class = "hyperparam.J"))
}
